{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ViTacVisDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(\"Train model.\")\n",
    "# parser.add_argument(\"--epochs\", type=int, help=\"Number of epochs.\", required=True)\n",
    "# parser.add_argument(\"--data_dir\", type=str, help=\"Path to data.\", required=True)\n",
    "# parser.add_argument(\n",
    "#     \"--checkpoint_dir\", type=str, help=\"Path for saving checkpoints.\", required=True\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\"--lr\", type=float, help=\"Learning rate.\", required=True)\n",
    "# parser.add_argument(\n",
    "#     \"--sample_file\", type=int, help=\"Sample number to train from.\", required=True\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--batch_size\", type=int, help=\"Batch Size.\", required=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS():\n",
    "    def __init__(self):\n",
    "        self.data_dir = '/home/tasbolat/some_python_examples/data_VT_SNN/'\n",
    "        self.batch_size = 8\n",
    "        self.sample_file = 1\n",
    "        self.lr = 0.01\n",
    "        self.epochs = 2000\n",
    "        self.output_size = 20\n",
    "args = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ViTacVisDataset(\n",
    "    path=args.data_dir, sample_file=f\"train_80_20_{args.sample_file}.txt\", output_size=args.output_size\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "test_dataset = ViTacVisDataset(\n",
    "    path=args.data_dir, sample_file=f\"test_80_20_{args.sample_file}.txt\", output_size=args.output_size\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3D(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN3D, self).__init__()\n",
    "        self.input_size = 8*5*3\n",
    "        self.hidden_dim = 32\n",
    "        self.num_layers = 1\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=2, out_channels=2, kernel_size=(5,5,5), stride=(3,2,2))\n",
    "        self.conv2 = nn.Conv3d(in_channels=2, out_channels=4, kernel_size=(5,3,3), stride=(3,2,2))\n",
    "        self.conv3 = nn.Conv3d(in_channels=4, out_channels=8, kernel_size=(5,3,3), stride=(3,2,2))\n",
    "\n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(np.prod([8, 11, 6, 5]), 20)\n",
    "        \n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        #self.fc_mlp = nn.Linear(6300, self.input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print('Model input ', x.size())\n",
    "        batch_size, C, H, W, sequence_size = x.size()\n",
    "        x = x.view([batch_size, C, sequence_size, H, W])\n",
    "        #print('Model input ', x.size())\n",
    "        \n",
    "        # pass to cnn3d\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        #print('conv1 out: ', out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        #print('conv2 out: ', out.shape)\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        #print('conv3 out: ', out.shape)\n",
    "        out = out.view([batch_size, np.prod([8, 11, 6, 5])])\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = self.drop(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN3D().to(device)\n",
    "# Create snn loss instance.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define optimizer module.\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train: 1.0 Test: 0.55\n",
      "10 Train: 1.0 Test: 0.6\n",
      "20 Train: 1.0 Test: 0.6\n",
      "30 Train: 1.0 Test: 0.5833333333333334\n",
      "40 Train: 1.0 Test: 0.6166666666666667\n",
      "50 Train: 1.0 Test: 0.6166666666666667\n",
      "60 Train: 1.0 Test: 0.6\n",
      "70 Train: 1.0 Test: 0.6\n",
      "80 Train: 1.0 Test: 0.5833333333333334\n",
      "90 Train: 1.0 Test: 0.6333333333333333\n",
      "100 Train: 1.0 Test: 0.6\n",
      "110 Train: 1.0 Test: 0.6333333333333333\n",
      "120 Train: 1.0 Test: 0.6166666666666667\n",
      "130 Train: 1.0 Test: 0.6166666666666667\n",
      "140 Train: 1.0 Test: 0.65\n",
      "150 Train: 1.0 Test: 0.6333333333333333\n",
      "160 Train: 1.0 Test: 0.6166666666666667\n",
      "170 Train: 1.0 Test: 0.6333333333333333\n",
      "180 Train: 1.0 Test: 0.6333333333333333\n",
      "190 Train: 1.0 Test: 0.6333333333333333\n",
      "200 Train: 1.0 Test: 0.65\n",
      "210 Train: 1.0 Test: 0.6333333333333333\n",
      "220 Train: 1.0 Test: 0.65\n",
      "230 Train: 1.0 Test: 0.6833333333333333\n",
      "240 Train: 1.0 Test: 0.6666666666666666\n",
      "250 Train: 1.0 Test: 0.6666666666666666\n",
      "260 Train: 1.0 Test: 0.65\n",
      "270 Train: 1.0 Test: 0.65\n",
      "280 Train: 1.0 Test: 0.6333333333333333\n",
      "290 Train: 1.0 Test: 0.7\n",
      "300 Train: 1.0 Test: 0.6833333333333333\n",
      "310 Train: 1.0 Test: 0.6333333333333333\n",
      "320 Train: 1.0 Test: 0.6833333333333333\n",
      "330 Train: 1.0 Test: 0.6333333333333333\n",
      "340 Train: 1.0 Test: 0.6666666666666666\n",
      "350 Train: 1.0 Test: 0.65\n",
      "360 Train: 1.0 Test: 0.6666666666666666\n",
      "370 Train: 1.0 Test: 0.6833333333333333\n",
      "380 Train: 1.0 Test: 0.6666666666666666\n",
      "390 Train: 1.0 Test: 0.6166666666666667\n",
      "400 Train: 1.0 Test: 0.6833333333333333\n",
      "410 Train: 1.0 Test: 0.65\n",
      "420 Train: 1.0 Test: 0.65\n",
      "430 Train: 1.0 Test: 0.65\n",
      "440 Train: 1.0 Test: 0.7166666666666667\n",
      "450 Train: 1.0 Test: 0.6833333333333333\n",
      "460 Train: 1.0 Test: 0.6666666666666666\n",
      "470 Train: 1.0 Test: 0.7\n",
      "480 Train: 1.0 Test: 0.6166666666666667\n",
      "490 Train: 1.0 Test: 0.7\n",
      "500 Train: 1.0 Test: 0.6666666666666666\n",
      "510 Train: 1.0 Test: 0.7\n",
      "520 Train: 1.0 Test: 0.6666666666666666\n",
      "530 Train: 1.0 Test: 0.6666666666666666\n",
      "540 Train: 1.0 Test: 0.65\n",
      "550 Train: 1.0 Test: 0.6333333333333333\n",
      "560 Train: 1.0 Test: 0.65\n",
      "570 Train: 1.0 Test: 0.7166666666666667\n",
      "580 Train: 1.0 Test: 0.7166666666666667\n",
      "590 Train: 1.0 Test: 0.65\n",
      "600 Train: 1.0 Test: 0.6166666666666667\n",
      "610 Train: 1.0 Test: 0.6833333333333333\n",
      "620 Train: 1.0 Test: 0.7166666666666667\n",
      "630 Train: 1.0 Test: 0.7\n",
      "640 Train: 1.0 Test: 0.6833333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea407e397ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Forward pass of the network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_viz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_accs = []\n",
    "# test_accs = []\n",
    "# train_loss = []\n",
    "# test_loss = []\n",
    "for epoch in range(args.epochs):\n",
    "    # Training loop.\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    batch_loss = 0\n",
    "    train_acc = 0\n",
    "    for i, (in_viz, _, label) in enumerate(train_loader, 0):\n",
    "\n",
    "        in_viz = in_viz.to(device)\n",
    "        label = label.to(device)\n",
    "        # Forward pass of the network.\n",
    "        #print(in_viz.shape)\n",
    "        out = net.forward(in_viz)\n",
    "        #print(out_tact.shape)\n",
    "        # Calculate loss.\n",
    "        #print(label.shape)\n",
    "        loss = criterion(out, label)\n",
    "        #print(loss)\n",
    "\n",
    "        batch_loss += loss.cpu().data.item()\n",
    "        # Reset gradients to zero.\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass of the network.\n",
    "        loss.backward()\n",
    "        # Update weights.\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "    # Reset training stats.\n",
    "    train_acc = correct/len(train_loader.dataset)\n",
    "    train_loss.append(batch_loss/len(train_loader.dataset))\n",
    "    train_accs.append(train_acc)\n",
    "    #print(train_acc, batch_loss)\n",
    "    \n",
    "    # testing\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    batch_loss = 0\n",
    "    train_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (in_viz, _, label) in enumerate(train_loader, 0):\n",
    "            in_viz = in_viz.to(device)\n",
    "            # Forward pass of the network.\n",
    "            out = net.forward(in_viz)\n",
    "            label = label.to(device)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            # Calculate loss.\n",
    "            loss = criterion(out, label)\n",
    "            batch_loss += loss.cpu().data.item()\n",
    "    train_acc = correct/len(train_loader.dataset)\n",
    "\n",
    "    # testing\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    batch_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (in_viz, _, label) in enumerate(test_loader, 0):\n",
    "            in_viz = in_viz.to(device)\n",
    "            # Forward pass of the network.\n",
    "            out = net.forward(in_viz)\n",
    "            label = label.to(device)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            # Calculate loss.\n",
    "            loss = criterion(out, label)\n",
    "            batch_loss += loss.cpu().data.item()\n",
    "\n",
    "    test_loss.append(batch_loss/len(test_loader.dataset))\n",
    "    test_acc = correct/len(test_loader.dataset)\n",
    "    test_accs.append(test_acc)\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch, 'Train:', train_acc, 'Test:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,3))\n",
    "ax[0].plot(train_accs)\n",
    "ax[0].plot(test_accs)\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Test'])\n",
    "\n",
    "ax[1].plot(train_loss) \n",
    "ax[1].plot(test_loss)\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
