{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../VT_SNN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import slayerSNN as snn\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from snn_models.baseline_snn import SlayerMLP\n",
    "from snn_models.multimodal_snn import EncoderTact\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ViTacDataset, ViTacMMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='../aux_rests/mm_old_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS():\n",
    "    def __init__(self):\n",
    "        self.data_dir = '/home/tasbolat/some_python_examples/data_VT_SNN_new/'\n",
    "        self.batch_size = 8\n",
    "        self.sample_file = 2\n",
    "        self.lr = 0.001\n",
    "        self.epochs = 500\n",
    "        self.output_size = 20\n",
    "        self.theta = 10\n",
    "        self.tauRho = 1\n",
    "        self.tsample= 325\n",
    "        self.tsr_stop = 325\n",
    "        self.sc_true = 150\n",
    "        self.sc_false = 5\n",
    "        self.hidden_size = 32\n",
    "args = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": args.theta, # activation threshold\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 1.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": args.tsample, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 325,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: args.sc_true, False: args.sc_false},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = args.output_size # 20\n",
    "\n",
    "train_dataset = ViTacMMDataset(\n",
    "    path=args.data_dir, sample_file=f\"train_80_20_{args.sample_file}.txt\", output_size=args.output_size\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "test_dataset = ViTacMMDataset(\n",
    "    path=args.data_dir, sample_file=f\"test_80_20_{args.sample_file}.txt\", output_size=args.output_size\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([156, 1, 1, 325]), torch.Size([2, 63, 50, 325]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c, d = test_dataset[0]\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.]), tensor([0., 1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(a), torch.unique(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderVis(torch.nn.Module):\n",
    "    def __init__(self, netParams, output_size):\n",
    "        super(EncoderVis, self).__init__()\n",
    "        self.slayer = snn.layer(netParams['neuron'], netParams['simulation'])\n",
    "        self.fc1   = self.slayer.dense((50, 63, 2), output_size)\n",
    "    def forward(self, downsampled):\n",
    "        #spikeLayer1 = self.slayer.spike(self.slayer.psp(downsampled)) # 32, 32, 16\n",
    "        spikeLayer5 = self.slayer.spike(self.fc1(self.slayer.psp(downsampled))) #  10\n",
    "        #self.spike_trains = [spikeLayer1]\n",
    "        return spikeLayer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlayerMM(torch.nn.Module):\n",
    "    def __init__(self, netParams, output_size):\n",
    "        super(SlayerMM, self).__init__()\n",
    "        slayer = snn.layer(netParams['neuron'], netParams['simulation'])\n",
    "        self.tactile = EncoderTact(netParams, 50)\n",
    "        self.vision = EncoderVis(netParams, 10)\n",
    "        self.slayer = slayer\n",
    "        self.fc1   = slayer.dense(60, output_size)\n",
    "\n",
    "    def forward(self, spikeInputTact, spikeInputVis):\n",
    "        spikeLayer1 = self.tactile(spikeInputTact)\n",
    "        spikeLayer2 = self.vision(spikeInputVis)\n",
    "        spikeAll = torch.cat([spikeLayer1, spikeLayer2], dim=1)\n",
    "        #self.spike_trains = [spikeAll] + self.tactile.spike_trains + self.vision.spike_trains\n",
    "\n",
    "        out = self.slayer.spike(self.slayer.psp(self.fc1(spikeAll)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = SlayerMM(params, args.output_size).to(device)\n",
    "\n",
    "error = snn.loss(params).to(device)\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    net.parameters(), lr=args.lr, weight_decay=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlayerMM(\n",
       "  (tactile): EncoderTact(\n",
       "    (slayer): spikeLayer()\n",
       "    (fc1): _denseLayer(156, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (vision): EncoderVis(\n",
       "    (slayer): spikeLayer()\n",
       "    (fc1): _denseLayer(2, 10, kernel_size=(63, 50, 1), stride=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (slayer): spikeLayer()\n",
       "  (fc1): _denseLayer(60, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Accs (train, test): 0.26875 0.225\n",
      "Loss (train, test): 28.063404726982117 27.79113483428955\n",
      "Epoch: 20\n",
      "Accs (train, test): 0.4625 0.35\n",
      "Loss (train, test): 23.424457252025604 25.26361656188965\n",
      "Epoch: 30\n",
      "Accs (train, test): 0.60625 0.4\n",
      "Loss (train, test): 19.404740780591965 23.61580753326416\n",
      "Epoch: 40\n",
      "Accs (train, test): 0.709375 0.55\n",
      "Loss (train, test): 16.31387076973915 21.808212661743163\n",
      "Epoch: 50\n",
      "Accs (train, test): 0.809375 0.575\n",
      "Loss (train, test): 13.718462127447129 20.849654865264892\n",
      "Epoch: 60\n",
      "Accs (train, test): 0.878125 0.575\n",
      "Loss (train, test): 11.498779529333115 20.53523197174072\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    tr_correct = 0\n",
    "    btr_loss = 0\n",
    "    net.train()\n",
    "    for i, (tac, vis, target, label) in enumerate(train_loader):\n",
    "        tac = tac.to(device)\n",
    "        vis = vis.to(device)\n",
    "        target = target.to(device)\n",
    "        output = net.forward(tac, vis)\n",
    "        tr_correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        loss = error.numSpikes(output, target)\n",
    "        btr_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Evaluate\n",
    "    te_correct = 0\n",
    "    bte_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (tac, vis, target, label) in enumerate(test_loader):\n",
    "            tac = tac.to(device)\n",
    "            vis = vis.to(device)\n",
    "            target = target.to(device)\n",
    "            output = net.forward( tac, vis)\n",
    "            te_correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            loss = error.numSpikes(output, target)\n",
    "            bte_loss += loss.item()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch:', epoch)    \n",
    "        print('Accs (train, test):', tr_correct/len(train_dataset), te_correct/len(test_dataset))\n",
    "        print('Loss (train, test):', btr_loss/len(train_dataset), bte_loss/len(test_dataset))\n",
    "    \n",
    "    train_loss.append( btr_loss/len(train_dataset) )\n",
    "    test_loss.append( bte_loss/len(test_dataset) )\n",
    "    train_acc.append( tr_correct/len(train_dataset) )\n",
    "    test_acc.append( te_correct/len(test_dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2,figsize=(8,6))\n",
    "ax[0].plot(train_acc, 'b')\n",
    "ax[0].plot(test_acc, 'r')\n",
    "ax[0].legend(['Train', 'Test'])\n",
    "\n",
    "ax[1].plot(train_loss, 'b')\n",
    "ax[1].plot(test_loss, 'r')\n",
    "ax[1].legend(['Train', 'Test'])\n",
    "plt.tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([train_acc, test_acc, train_loss, test_loss], open(fname + '.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), fname+'.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
